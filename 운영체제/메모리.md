# 메모리

## 개념
- 넓은 의미 : 전자회로에서 데이터나 상태, 명령어 등을 기록(기억)하는 모든 장치
- 좁은 의미 : RAM (Random Access Memory)
- CPU는 RAM(이하 램)에 올라와있는 프로그램(=프로세스)의 명령어들을 실행함.

***

## 메모리 계층
- 계층화의 이유 : CPU가 일을 더 효율적으로 처리하기 위함. 

![image](https://user-images.githubusercontent.com/66233687/196105701-70290ffd-6fd6-4cd6-976f-4788940b6be6.png)

### 레지스터
- CPU 내부에 위치, 제일 빠른 메모리
- CPU가 요청을 처리하는 데 필요한 데이터를 일시적으로 저장
- CPU는 자체적으로 데이터를 저장할 방법이 없으므로 메모리로 직접 데이터를 전송할 수 없음 → 연산을 위해서 반드시 레지스터를 거쳐야 하며, 이를 위해 레지스터는 특정 주소를 가리키거나 값을 읽어올 수 있음
- 프로세스가 바로 사용할 수 있는 데이터(소량의 데이터, 처리 중인 중간 결과 등)를 담고 있는 영역

### 캐시
- L1, L2 캐시는 CPU 내부에 / L3 캐시는 대부분 CPU가 아닌 메인보드에 내장
- 데이터를 미리 복사해 놓는 임시 저장소
- 메모리의 데이터 중 자주 사용하는 데이터나 계산한 값 등을 캐시에 저장해놓음(=캐싱) → 평균 메모리 접근 시간을 아낄 수 있음
- CPU가 메인 메모리의 데이터에 접근할 때는 먼저 그 주소에 해당하는 데이터가 캐시에 존재하는지를 살피고, 캐시에 있으면 데이터를 캐시에서 읽고, 그렇지 않으면 메인 메모리에접근
- 속도와 용량에 따라 L1, L2, L3 캐시로 분류 (L1이 가장 작고 빠름)

#### 캐시 히트 VS 캐시 미스

![image](https://user-images.githubusercontent.com/66233687/196105579-5c461bfc-37dd-4e49-8b0f-ae0ddde0d9d5.png)

### 주기억장치(Main Memory)
- CPU 외부에 위치 : CPU가 레지스터나 캐시보다 더 느리게 접근

#### RAM (Random Access Memory)
- Random Access : 어느 위치에서든 똑같은 속도로 접근하여 읽고 쓸 수 있다는 의미
- 컴퓨터가 빠른 액세스를 하기 위해 데이터를 단기간 저장하는 구성 요소
- 사용자가 요청하는 프로그램이나 문서를 스토리지 디스크에서 메모리로 로드하여 각각의 정보에 액세스
- 컴퓨터 전원이 유지되는 동안 CPU의 연산 및 동작에 필요한 모든 내용이 저장
- 컴퓨터 전원 종료시 기억된 내용 삭제

#### ROM (Read Only Memory)
- 한 번 기록한 데이터를 빠른 속도로 읽을 수는 있지만, 기록 및 수정은 할 수 없음 
- 전원이 공급되지 않아도 기록된 정보가 지워지지 않는 비휘발성 메모리(Non-Volatile Memory)
- 실제로 주기억장치로 사용되기보다는 주로 기본 입,출력 시스템(BIOS), 자가 진단 프로그램(POST)같은 변경 가능성이 희박한 시스템 소프트웨어를 기억시키는데 이용

### 보조기억장치
- CPU 외~부에 위치 : CPU 접근 불가
- 보조기억장치의 데이터를 메모리로 이동시키고, 메모리에 CPU가 접근하는 방식

#### HDD (Hard Disk Drive)
- 하드 디스크(Hard Disk), 하드 드라이브(Hard Drive), 고정 디스크(Fixed Drive)
- 비휘발성, 순차접근이 가능한 컴퓨터의 보조 기억 장치
- 비휘발성 데이터 저장소 가운데 가장 대중적이며 용량 대비 가격이 가장 저렴
- 보호 케이스 내부의 플래터를 회전 → 플래터에 자기 패턴으로 정보 기록
- 플래터 표면의 코팅된 자성체에 데이터 기록
- 회전하는 플래터 위에 부상하는 입출력 헤드에 의해 자기적으로 데이터 기록 및 조회 가능

#### SSD (Solide State Drive)
- 순수 전자식으로 작동하므로 기계식인 하드 디스크 드라이브(HDD)의 문제인 긴 탐색 시간, 반응 시간, 기계적 지연, 실패율, 소음을 크게 줄여줌.

***

## 메모리 관리
- 컴퓨터 내의 한정된 메모리를 극한으로 사용하기 위함

#### 가상메모리
- 프로세스를 실행할 때 실행에 필요한 일부만 메모리에 로드하고 나머지는 디스크에 두는 것
- 기존에는 프로세스가 실행되는 코드의 전체를 메모리에 로드해야 했고, 메모리 용량보다 더 큰 프로그램은 실행시킬 수 없었음 : 그러나 실제로는 코드의 일부에서만 대부분의 시간을 사용하고, 프로세스는 특정 순간에는 항상 작은 양의 주소 공간을 사용했기 때문에 이러한 방식은 매우 비효율적
- 가상 메모리는 메모리가 실제 메모리보다 많아 보이게 하는 기술로, 어떤 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가지 않더라도 실행이 가능하다는 점에 착안하여 고안
- 결과적으로 메모리에 작은 양의 주소 공간만 있으면 충분히 프로세스를 수행할 수 있고, 그에 따라 더 많은 프로그램을 동시에 실행할 수 있게 됨.
- MMU(Memory Management Unit, 메모리 관리 장치) : 가상주소를 물리주소로 변환하고, 메모리를 보호하는 기능을 수행하는 메모리 관리 하드웨어

#### Swapping
- 사용하지 않는 프로세스을 하드디스크로 옮기고, 필요할 때 해당 프로세스를 다시 메모리로 불러와 올림
- Swapping와 Demanding Paging은 둘 다 메모리와 backing store 사이를 서로 오고 가는 기능을 수행
- Swapping은 프로세스 단위로 이동 / Demanding Paging은 페이지 단위로 이동
> 사실 스와핑은 현재는 사용하지 않습니다. 프로세스 단위로 스와핑을 하면 비효율적이기 때문이죠. ...  가상 메모리를 관리하는 과정에서는 프로세스 단위로 스와핑하지 않고, 페이징 단위로 스와핑을 실행합니다. 
> https://resilient-923.tistory.com/m/397
- 프로세스나 페이지에 관계없이 교체 그 자체를 그냥 Swapping이라고 하기도 함.
<img src="https://user-images.githubusercontent.com/66233687/196199410-5aaf8610-d260-481e-b051-07a9d6c1f590.png" width="400px">

#### Demanding Paging(요구 페이징)
- 필요한 page만 메모리에 올리는 것
> page : 가상 메모리를 사용하는 최소 크기 단위

<img src="https://user-images.githubusercontent.com/66233687/196191594-9b15adfb-3cfe-4510-8bed-80d1fc911fb7.png" width="500px"> <img src="https://user-images.githubusercontent.com/66233687/196192081-8bb39611-fb45-4a7e-9bea-2149217fd8cb.png" width="500px">

#### Page Fault(페이지 부재)
- CPU가 접근하려는 페이지가 메모리에 없는 경우 : 페이지 테이블의 valid bit값이 0인 경우

![image](https://user-images.githubusercontent.com/66233687/196193601-ab98116a-ba84-4060-91d1-b8c000293b78.png)

**페이지 폴트 발생 시 처리 과정**
1. 해당 페이지가 메모리에 있는지 valid bit를 확인
2. valid bit가 0이라면 CPU에 인터럽트 신호를 보내어 운영체제 내부 해당 ISR로 점프
3. 해당 ISR에서 backing store(디스크)를 탐색하여 해당 프로세스의 페이지를 탐색
4. 해당 페이지를 비어있는 프레임에 할당
5. 페이지 테이블을 갱신 (프레임 번호 설정, valid bit 1로 변경)
6. 다시 명령어로 돌아가서 실행

#### Page Replacement(페이지 교체)
- 이미 메모리에 있는 페이지 중 하나를 다시 backing store에 보내고(page-out), 새로운 페이지를 메모리에 올리는(page-in) 것
- victim page : backing store로 page-out이 된 페이지

##### 페이지 교체 알고리즘
- 필요한 페이지가 메모리에 없을 때 page-falut가 발생하고 Backing Store에서 해당 페이지를 찾아 빈 프레임에 로딩해야 하는데, 이때 빈 프레임이 없을 경우 희생 당할 프레임(victim frame)을 고르는 알고리즘이 페이지 교체 알고리즘
- 이미 메모리에 있는 페이지 중 하나를 다시 backing store에 보내고(page-out), 새로운 페이지를 메모리에 올리는(page-in) 방법
- victim page : backing store로 page-out이 된 페이지
- 알고리즘의 목표는 페이지 부재율을 최소화가 목표 = 가까운 미래에 참조될 가능성이 가장 적은 페이지를 선택해서 내보내는 것

##### 1. OPT : Optimal
- 먼 미래에 참조되는 페이지와 현재 할당하는 페이지 교체 - 실제로 구현 불가능하지만, 다른 알고리즘 성능의 절대적 지표가 됨.

##### 2. FIFO : First In First Out 
- 가장 먼저 온 페이지를 교체
- 참조에 대한 고려를 하지 않으므로, 메모리를 증가해도 페이지 부재가 더 증가하는 FIFO의 이상 현상(FIFO abnomaly)이 발생할 수 있음
![image](https://user-images.githubusercontent.com/66233687/196359893-a1d210b5-ba86-49c6-a2a3-60d606235f74.png)

##### 3. LRU : Least Recently Used
- 참조가 가장 오래된 페이지를 교체 / '오래된' 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어야하는 문제

##### 4. NUR : Not Used Recently 
- LRU에서 발전
- Clock 알고리즘
![image](https://user-images.githubusercontent.com/66233687/196357840-062291b5-2644-4e55-bae7-2284d057e9fa.png)
참조 비트(reference bit)를 순차적으로 조사하며 동작
1. 프레임 내의 페이지가 참조될 때 하드웨어에 의해 1로 자동 세팅
2. 클럭 알고리즘은 한 바퀴 돌며 참조되지 않은 페이지의 참조 비트 값을 0으로 바꾼 후 지나감
3. 참조 비트가 0인 페이지를 방문하면 해당 페이지를 교체

##### 5. LFU : Least Frequently Used 
- 참조 횟수가 가장 적은 페이지 교체 (많이 사용되지 않은 것을 교체)

***

## Reference
### 메모리 계층 관련
- https://velog.io/@yu-jin-song/CS-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B3%84%EC%B8%B5-%EA%B5%AC%EC%A1%B0
- https://velog.io/@ckstn0777/%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-75yk3fno
- http://keepcalmswag.blogspot.com/2018/06/cache.html

### 메모리 관리 관련
- https://rebro.kr/m/179
- https://velog.io/@codemcd/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-15.-%EA%B0%80%EC%83%81%EB%A9%94%EB%AA%A8%EB%A6%AC
- 페이지 교체 알고리즘 https://zangzangs.tistory.com/m/143
